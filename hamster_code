{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries!\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cascPath = \"./haarcascade_eye.xml\"\n",
    "cascPath = \"./haarcascade_frontalface_default.xml\"\n",
    "# cascPath = \"./haarcascade_frontalface_alt_tree.xml\"\n",
    "# cascPath = \"./haarcascade_frontalface_alt.xml\"\n",
    "# cascPath = \"./haarcascade_profileface_newer.xml\"\n",
    "\n",
    "faceCascade = cv.CascadeClassifier(cascPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay_image_alpha(img, img_overlay_in, x, y, w, output_file):\n",
    "    \"\"\"Overlay `img_overlay` onto `img` at (x, y) and blend using `alpha_mask`.\n",
    "\n",
    "    `alpha_mask` must have same HxW as `img_overlay` and values in range [0, 1].\n",
    "    \"\"\"\n",
    "    # Image prep\n",
    "\n",
    "    imgNew = np.array(Image.open(img))\n",
    "    img_copy = imgNew[:, :, :3].copy()\n",
    "\n",
    "    img_overlay_in_resized = resize_img(img_overlay_in, w, \"resized_img.png\") \n",
    "    img_overlay_rgba = np.array(Image.open(img_overlay_in_resized))\n",
    "    alpha_mask = img_overlay_rgba[:, :, 3] / 255.0\n",
    "    \n",
    "    img_overlay = img_overlay_rgba[:, :, :3]\n",
    "\n",
    "    # Image ranges\n",
    "    y1, y2 = max(0, y), min(img_copy.shape[0], y + img_overlay.shape[0])\n",
    "    x1, x2 = max(0, x), min(img_copy.shape[1], x + img_overlay.shape[1])\n",
    "\n",
    "    # Overlay ranges\n",
    "    y1o, y2o = max(0, -y), min(img_overlay.shape[0], img_copy.shape[0] - y)\n",
    "    x1o, x2o = max(0, -x), min(img_overlay.shape[1], img_copy.shape[1] - x)\n",
    "\n",
    "    # Exit if nothing to do\n",
    "    if y1 >= y2 or x1 >= x2 or y1o >= y2o or x1o >= x2o:\n",
    "        return\n",
    "\n",
    "    # Blend overlay within the determined ranges\n",
    "    img_crop = img_copy[y1:y2, x1:x2]\n",
    "    img_overlay_crop = img_overlay[y1o:y2o, x1o:x2o]\n",
    "    alpha = alpha_mask[y1o:y2o, x1o:x2o, np.newaxis]\n",
    "    alpha_inv = 1.0 - alpha\n",
    "\n",
    "    img_crop[:] = alpha * img_overlay_crop + alpha_inv * img_crop\n",
    "\n",
    "    Image.fromarray(img_copy).save(output_file)\n",
    "    os.remove(\"resized_img.png\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_img(img_in, w, img_out):\n",
    "    img = Image.open(img_in)\n",
    "\n",
    "    basewidth = w\n",
    "    wpercent = (basewidth/float(img.size[0]))\n",
    "    hsize = int((float(img.size[1])*float(wpercent)))\n",
    "    img = img.resize((basewidth,hsize), Image.ANTIALIAS)\n",
    "    img.save(img_out)\n",
    "    return img_out\n",
    "\n",
    "# resize_img(\"hamster1.png\", 100, \"hamster1resized.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Note on round detection:\n",
    "# while we looked into attepmts at using opencv2's find circle features, our project was built around using a trained model to find objects to replace, and implementing a whole other\n",
    "# method would be reworking our project from the ground, which we felt was too much to do at this stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hamsterize_img(img_in):\n",
    "    image_faces_rgb = cv.imread(img_in)\n",
    "    image_faces_gray = cv.cvtColor(image_faces_rgb, cv.COLOR_RGB2GRAY)\n",
    "    faces = faceCascade.detectMultiScale(\n",
    "        image_faces_gray,       # this is the input image\n",
    "        scaleFactor=1.05,       # this is the scale-resolution for detecting faces\n",
    "        minNeighbors=1,         # this is how many nearby-detections are needed to ok a face\n",
    "        minSize=(10,10),        # this is the minimum size for a face\n",
    "        flags = cv.CASCADE_SCALE_IMAGE,   # (standard)\n",
    "    )\n",
    "    for i, face in enumerate(faces):\n",
    "        x,y,w,h = face\n",
    "\n",
    "    img = Image.open(img_in)\n",
    "    output_file = img_in[:-4] + \"_hamsterized\" + img_in[-4:]\n",
    "    img_overlay = \"hamster1.png\"\n",
    "    img.save(output_file)\n",
    "    input_file = output_file\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        overlay_image_alpha(input_file, img_overlay, x, y, w, output_file)\n",
    "\n",
    "\n",
    "    # show the image!\n",
    "    # Image.open(output_file).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "hamsterize_img(\"spaghetti_night.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
